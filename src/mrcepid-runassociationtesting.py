#!/usr/bin/env python
# mrcepid-runnassociationtesting 0.0.1
# Generated by dx-app-wizard.
#
# Author: Eugene Gardner (eugene.gardner at mrc.epid.cam.ac.uk)
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import dxpy
import csv
import subprocess
import tarfile
import pandas as pd
import statsmodels.api as sm
import numpy as np
import os
from os.path import exists
from concurrent import futures
from concurrent.futures import ThreadPoolExecutor


# This is to generate a global CHROMOSOMES variable for parallelisation
CHROMOSOMES = list(range(1,23)) # Is 0 based on the right coordinate...? (So does 1..22)
CHROMOSOMES.extend(['X'])
CHROMOSOMES = list(map(str, CHROMOSOMES))


# This function runs a command on an instance, either with or without calling the docker instance we downloaded
# By default, commands are not run via Docker, but can be changed by setting is_docker = True
# Also, by default, standard out is not saved, but can be modified with the 'stdout_file' parameter.
def run_cmd(cmd: str, is_docker: bool = False, stdout_file: str = None) -> None:

    # -v here mounts a local directory on an instance (in this case the home dir) to a directory internal to the
    # Docker instance named /test/. This allows us to run commands on files stored on the AWS instance within Docker.
    # This looks slightly different from other versions of this command I have written as I needed to write a custom
    # R script to run STAAR. That means we have multiple mounts here to enable this code to find the script.
    if is_docker:
        cmd = "docker run " \
              "-v /home/dnanexus:/test " \
              "-v /usr/bin/:/prog " \
              "egardner413/mrcepid-associationtesting " + cmd

    # Standard python calling external commands protocol
    print(cmd)
    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()
    if stdout_file is not None:
        with open(stdout_file, 'w') as stdout_writer:
            stdout_writer.write(stdout.decode('utf-8'))
        stdout_writer.close()

    # If the command doesn't work, print the error stream and close the AWS instance out with 'dxpy.AppError'
    if proc.returncode != 0:
        print("The following cmd failed:")
        print(cmd)
        print("STDERROR follows\n")
        print(stderr.decode('utf-8'))
        raise dxpy.AppError("Failed to run properly...")


# This function is slightly different that in other applets I have designed. This function handles ALL inputs rather
# than just external dependencies
def ingest_data(association_tarball: str, phenofile: str, covarfile: str, inclusion_list: str, exclusion_list: str) -> dict:

    # Need to grab the tarball file for associations...
    # This was generated by the applet mrcepid-mergecollapsevariants
    tarball = dxpy.DXFile(association_tarball)
    tarball_name = tarball.describe()['name']
    dxpy.download_dxfile(tarball, tarball_name)

    # Need to get the prefix on the tarball to access resources within:
    # All files within SHOULD have the same prefix as this file
    tarball_prefix = tarball_name.rstrip('.tar.gz')
    cmd = "tar -zxf " + tarball_name # unzip the tarball:
    run_cmd(cmd)

    # Now grab all genetic data that I have in the folder /project_resources/genetics/
    # This includes filtered plink files and masks
    # This was generated by mrcepid-buildgrms
    dxpy.download_folder('project-G6BJF50JJv8p4PjGB9yy7YQ2',
                         'genetics/',
                         folder = "/project_resources/genetics/")

    # Get phenotype data:
    dxpy.download_dxfile(dxid = 'file-G7PzVbQJJv8kz6QvP41pvKVg',
                         project = 'project-G6BJF50JJv8p4PjGB9yy7YQ2',
                         filename = 'base_covariates.covariates')
    dxpy.download_dxfile(dxpy.DXFile(phenofile), 'model_phenotypes.pheno')

    # Check if additional covariates were provided:
    additional_covariates_found = False
    if covarfile is not None:
        covarfile = dxpy.DXFile(covarfile)
        dxpy.download_dxfile(covarfile, 'additional_covariates.covariates')
        additional_covariates_found = True

    # Get inclusion/exclusion sample lists
    inclusion_found = False
    if inclusion_list is not None:
        inclusion_list = dxpy.DXFile(inclusion_list)
        dxpy.download_dxfile(inclusion_list, 'INCLUSION.lst')
        inclusion_found = True
    exclusion_found = False
    if exclusion_list is not None:
        exclusion_list = dxpy.DXFile(exclusion_list)
        dxpy.download_dxfile(exclusion_list, 'EXCLUSION.lst')
        exclusion_found = True

    return {'tarball_prefix': tarball_prefix,
            'inclusion_found': inclusion_found,
            'exclusion_found': exclusion_found,
            'additional_covariates_found': additional_covariates_found}


# Three steps here:
# 1. Get individuals we plan to include
# 2. Exclude individuals not wanted in the analysis
# 3. Get individuals that are POSSIBLE to include (they actually have WES) and only keep 'include' samples
def select_individuals(inclusion_found: bool, exclusion_found: bool) -> set:

    # Get a list of individuals that we ARE going to use
    include_samples = set()
    if inclusion_found is True:
        inclusion_file = open('INCLUSION.lst', 'r')
        for indv in inclusion_file:
            indv = indv.rstrip()
            include_samples.add(indv)

    # Get a list of individuals that we ARE NOT going to use
    exclude_samples = set()
    if exclusion_found is True:
        exclude_file = open('EXCLUSION.lst', 'r')
        for indv in exclude_file:
            indv = indv.rstrip()
            exclude_samples.add(indv)

    # Get individuals with genetic data
    # Remember! the genetic data has already been filtered to individuals with WES data.
    genetics_fam_file = open('genetics/UKBB_450K_Autosomes_QCd.fam', 'r')
    genetics_samples = set()
    for line in genetics_fam_file:
        line = line.rstrip()
        fields = line.split()
        eid = fields[0]
        if inclusion_found == False and exclusion_found == False:
            genetics_samples.add(eid)
        elif inclusion_found == False and exclusion_found == True:
            if eid not in exclude_samples:
                genetics_samples.add(eid)
        elif inclusion_found == True and exclusion_found == False:
            if eid in include_samples:
                genetics_samples.add(eid)
        else:
            if eid in include_samples and eid not in exclude_samples:
                genetics_samples.add(eid)

    print("Total samples after inclusion/exclusion lists applied: %i" % len(genetics_samples))
    return genetics_samples


# This is a helper function for 'create_covariate_file()' that processes the phenotype file
def process_phenotype() -> tuple:
    # Need to go through phenofile first and injest into a dictionary and get the name of the phenofield:
    pheno_reader = csv.DictReader(open('model_phenotypes.pheno', 'r'), delimiter="\t")
    field_names = pheno_reader.fieldnames
    if len(field_names) != 3:
        raise RuntimeError("Pheno file has more than three columns!")
    elif "FID" not in field_names and "IID" not in field_names:
        raise RuntimeError("Pheno file has column names other than FID/IID/Phenotype!")

    for field in field_names:
        if field != "FID" and field != "IID":
            pheno_name = field

    phenotypes = {}
    for indv in pheno_reader:
        # Will spit out an error if a given sample does not have data
        if indv[pheno_name] is None:
            raise dxpy.AppError("Phenotype file has blank lines!")
        # Exclude individuals that have missing data (NA/NAN)
        elif indv[pheno_name].lower() != "na" and indv[pheno_name].lower() != "nan" and indv[pheno_name].lower() != "":
            phenotypes[indv['FID']] = indv[pheno_name]

    return phenotypes, pheno_name


# This is a helper function for 'create_covariate_file()' that processes requested additional phenotypes
def process_additional_covariates(additional_covariates_found: bool, categorical_covariates: str, quantitative_covariates: str) -> tuple:

    if additional_covariates_found:
        additional_covar_reader = csv.DictReader(open('additional_covariates.covariates', 'r'), delimiter="\t")
        field_names = list.copy(additional_covar_reader.fieldnames)

        # make sure the sample ID field is here and remove it from 'field_names' to help with iteration
        if 'eid' not in field_names:
            raise dxpy.AppError("eid column not found in provided covariates file!")
        else:
            field_names.remove('eid')

        # Now process & check the categorical/quantitative covariates lists and match it to field_names:
        found_categorical_covariates = []
        categorical_covariates = categorical_covariates.split(',')
        for covar in categorical_covariates:
            # print(covar)
            if covar in field_names:
                found_categorical_covariates.append(covar)
            else:
                print("Provided categorical covariate %s not found in additional covariates file..." % covar)

        found_quantitative_covariates = []
        quantitative_covariates = quantitative_covariates.split(',')
        for covar in quantitative_covariates:
            print(covar)
            if covar in field_names:
                found_quantitative_covariates.append(covar)
            else:
                print("Provided quantitative covariate %s not found in additional covariates file..." % covar)

        # Throw an error if user provided covariates but none were found
        if (len(found_categorical_covariates) + len(found_quantitative_covariates)) == 0:
            raise dxpy.AppError('Additional covariate file provided but no additional covariates found based on covariate names provided...')

        add_covars = {}
        for sample in additional_covar_reader:
            # First check no NAs/Blanks exist
            all_covars_found = True
            sample_dict = {}
            for field_name in (found_quantitative_covariates + found_categorical_covariates):
                if sample[field_name].lower() == "na" or sample[field_name].lower() == "nan" or sample[field_name].lower() == "":
                    all_covars_found = False
                else:
                    sample_dict[field_name] = sample[field_name]

            if all_covars_found == True:
                add_covars[sample['eid']] = sample_dict

        return add_covars, found_quantitative_covariates, found_categorical_covariates
    else:
        return {}, [], []


# Do covariate processing and sample inclusion/exclusion
def create_covariate_file(sex: int, genetics_samples: set, additional_covariates_found: bool, categorical_covariates: str,
                          quantitative_covariates: str) -> dict:

    # Process the phenotype:
    phenotypes, pheno_name = process_phenotype()

    # Process additional covariates (check if requested in the function):
    add_covars, found_quantitative_covariates, found_categorical_covariates = process_additional_covariates(additional_covariates_found,
                                                                                                            categorical_covariates,
                                                                                                            quantitative_covariates)
    # Read the base covariates into this code that we want to analyse:
    # Formatting is weird to fit with other printing below...
    print("Default covariates included in model                        :")
    print("    Quantitative                                            : age, age^2, PC1..PC10")
    if (sex == 2):
        print("    Categorical                                             : sex, WES_batch")
    else:
        print("    Categorical                                             : WES_batch")
    if additional_covariates_found:
        print("Number of individuals with non-null additional covariates   : %i" % len(add_covars))
        print("Additional covariates included in model                     :")
        if len(found_quantitative_covariates) > 0:
            print("    Quantitative                                            : " + ', '.join(found_quantitative_covariates))
        else:
            print("    Quantitative                                            : NULL")
        if len(found_quantitative_covariates) > 0:
            print("    Categorical                                             : " + ', '.join(found_categorical_covariates))
        else:
            print("    Categorical                                             : NULL")
    else:
        print("No additional covariates provided/found beyond defaults...")

    base_covar_reader = csv.DictReader(open('base_covariates.covariates', 'r'), delimiter="\t")
    indv_written = 0 # Just to count the number of samples we will analyse
    formatted_combo_file = open('phenotypes_covariates.formatted.txt', 'w') # SAIGE needs a combo file

    write_fields = ["FID", "IID"]
    write_fields = write_fields + ["PC%s" % (x) for x in range(1,41)]
    write_fields = write_fields + ["age", "age_squared", "sex", "wes_batch"]
    write_fields = write_fields + [pheno_name]
    # This doesn't matter to python if we didn't find additional covariates. A list of len() == 0 does not lengthen
    # the target list (e.g. 'write_fields')
    write_fields = write_fields + found_quantitative_covariates + found_categorical_covariates

    combo_writer = csv.DictWriter(formatted_combo_file,
                                  fieldnames = write_fields,
                                  quoting = csv.QUOTE_NONE,
                                  delimiter = " ",
                                  extrasaction='ignore')
    combo_writer.writeheader()

    # Need a list of included individuals ONLY:
    include_samples = open('SAMPLES_Include.txt', 'w')
    num_all_samples = 0
    na_pheno_samples = 0 # for checking number of individuals missing phenotype information
    for indv in base_covar_reader:
        if indv['22001-0.0'] != "": # need to exclude blank row individuals, eid is normally the only thing that shows up, so filter on sex
            indv_writer = {'FID': indv['eid'],
                           'IID': indv['eid']}
            for PC in range(1,41):
                old_PC = "22009-0.%s" % (PC)
                new_pc = "PC%s" % (PC)
                indv_writer[new_pc] = indv[old_PC]
            indv_writer['age'] = int(indv['21003-0.0'])
            indv_writer['age_squared'] = indv_writer['age']**2
            indv_writer['sex'] = int(indv['22001-0.0'])
            indv_writer['wes_batch'] = indv['wes.batch']

            # Check if we found additional covariates and make sure this sample has non-null values
            write_sample = False
            if len(add_covars) > 0:
                if indv['eid'] in add_covars:
                    write_sample = True
                    for covariate in add_covars[indv['eid']]:
                        indv_writer[covariate] = add_covars[indv['eid']][covariate]
            else:
                write_sample = True

            # exclude based on sex-specific analysis if required:
            if indv['eid'] in genetics_samples:
                num_all_samples += 1
                if indv['eid'] in phenotypes and write_sample:
                    indv_writer[pheno_name] = phenotypes[indv['eid']]
                    if sex == 2:
                        indv_written += 1
                        combo_writer.writerow(indv_writer)
                        include_samples.write(indv['eid'] + "\n")
                    elif sex == indv_writer['sex']:
                        indv_written += 1
                        combo_writer.writerow(indv_writer)
                        include_samples.write(indv['eid'] + "\n")
                else:
                    na_pheno_samples += 1

    formatted_combo_file.close()
    include_samples.close()

    # Generate a plink file to use that only has included individuals:
    cmd = "plink2 " \
          "--bfile /test/genetics/UKBB_450K_Autosomes_QCd --make-bed --keep-fam /test/SAMPLES_Include.txt " \
          "--out /test/genetics/UKBB_450K_Autosomes_QCd_WBA"
    run_cmd(cmd, True)

    # I have to do this to recover the sample information from plink
    cmd = "docker run -v /home/dnanexus/:/test/ egardner413/mrcepid-associationtesting plink2 " \
          "--bfile /test/genetics/UKBB_450K_Autosomes_QCd_WBA " \
          "--validate | grep samples"
    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()

    # Print to ensure that total number of individuals is consistent between genetic and covariate/phenotype data
    print("Samples with covariates after include/exclude lists applied : %i" % num_all_samples)
    print("Number of individuals with NaN/NA phenotype information     : %i" % na_pheno_samples)
    print("Number of individuals written to covariate/pheno file       : %i" % indv_written)
    print("Plink individuals written                                   : %s" % stdout.decode('utf-8').rstrip())

    # Return the phenotype name and additional covariates (if any) so we can use it later
    return {'pheno_name': pheno_name,
            'quant_covars': found_quantitative_covariates,
            'cat_covars': found_categorical_covariates}


# Run rare variant association testing using BOLT
def bolt(association_pack: dict) -> None:

    # # Need to pare down the bgen file to samples being tested
    with open('poss_chromosomes.txt', 'w') as poss_chromosomes:
        for chromosome in CHROMOSOMES:
            if exists(association_pack['tarball_prefix'] + "." + chromosome + ".BOLT.bgen"):
                poss_chromosomes.write("/test/%s /test/%s\n" % ("bolt_input." + chromosome + ".bgen", "bolt_input." + chromosome + ".sample"))
                cmd = "plink2 --bgen /test/" + association_pack['tarball_prefix'] + "." + chromosome + ".BOLT.bgen 'ref-last' " \
                         "--sample /test/" + association_pack['tarball_prefix'] + "." + chromosome + ".BOLT.sample " \
                         "--export bgen-1.2 'bits='8 " \
                         "--out /test/bolt_input." + chromosome + " " \
                         "--keep-fam /test/SAMPLES_Include.txt"
                run_cmd(cmd, True)
        poss_chromosomes.close()

    # See the README.md for more information on these parameters
    cmd = "bolt " + \
          "--bfile=/test/genetics/UKBB_450K_Autosomes_QCd_WBA " \
          "--exclude=/test/genetics/UKBB_450K_Autosomes_QCd.low_MAC.snplist " \
          "--phenoFile=/test/phenotypes_covariates.formatted.txt " \
          "--phenoCol=" + association_pack['pheno_name'] + " " \
          "--covarFile=/test/phenotypes_covariates.formatted.txt " \
          "--covarCol=sex " \
          "--covarCol=wes_batch " \
          "--qCovarCol=age " \
          "--qCovarCol=age_squared " \
          "--qCovarCol=PC{1:10} " \
          "--covarMaxLevels=110 " \
          "--LDscoresFile=BOLT-LMM_v2.3.5/tables/LDSCORE.1000G_EUR.tab.gz " \
          "--geneticMapFile=BOLT-LMM_v2.3.5/tables/genetic_map_hg19_withX.txt.gz " \
          "--lmmInfOnly " \
          "--numThreads=" + str(association_pack['threads']) + " " \
          "--statsFile=/test/" + association_pack['tarball_prefix'] + ".stats.gz " \
          "--verboseStats " \
          "--bgenSampleFileList=/test/poss_chromosomes.txt " \
          "--statsFileBgenSnps=/test/" + association_pack['tarball_prefix'] + ".bgen.stats.gz"
    if len(association_pack['quant_covars']) > 0:
        for covar in association_pack['quant_covars']:
            cmd += " --qCovarCol=" + covar + " "
    if len(association_pack['cat_covars']) > 0:
        for covar in association_pack['cat_covars']:
            cmd += " --covarCol=" + covar + " "
    run_cmd(cmd, True, association_pack['tarball_prefix'] + ".BOLT.log")

    # And now do per-marker tests as well:
    # I have to do this again because the names of files are slightly different (.markers.)
    with open('poss_chromosomes.txt', 'w') as poss_chromosomes:
        for chromosome in CHROMOSOMES:
            if exists(association_pack['tarball_prefix'] + "." + chromosome + ".BOLT.bgen"):
                poss_chromosomes.write("/test/%s /test/%s\n" % ("bolt_input.markers." + chromosome + ".bgen", "bolt_input.markers." + chromosome + ".sample"))
                cmd = "plink2 --bgen /test/" + association_pack['tarball_prefix'] + "." + chromosome + ".BOLT.markers.bgen 'ref-last' " \
                         "--sample /test/" + association_pack['tarball_prefix'] + "." + chromosome + ".BOLT.markers.sample " \
                         "--export bgen-1.2 'bits='8 " \
                         "--out /test/bolt_input.markers." + chromosome + " " \
                         "--keep-fam /test/SAMPLES_Include.txt"
                run_cmd(cmd, True)
        poss_chromosomes.close()

    cmd = "bolt " + \
          "--bfile=/test/genetics/UKBB_450K_Autosomes_QCd_WBA " \
          "--exclude=/test/genetics/UKBB_450K_Autosomes_QCd.low_MAC.snplist " \
          "--phenoFile=/test/phenotypes_covariates.formatted.txt " \
          "--phenoCol=" + association_pack['pheno_name'] + " " \
          "--covarFile=/test/phenotypes_covariates.formatted.txt " \
          "--covarCol=sex " \
          "--covarCol=wes_batch " \
          "--qCovarCol=age " \
          "--qCovarCol=age_squared " \
          "--qCovarCol=PC{1:10} " \
          "--covarMaxLevels=110 " \
          "--LDscoresFile=BOLT-LMM_v2.3.5/tables/LDSCORE.1000G_EUR.tab.gz " \
          "--geneticMapFile=BOLT-LMM_v2.3.5/tables/genetic_map_hg19_withX.txt.gz " \
          "--lmmInfOnly " \
          "--numThreads=" + str(association_pack['threads']) + " " \
          "--statsFile=/test/" + association_pack['tarball_prefix'] + ".markers.stats.gz " \
          "--verboseStats " \
          "--bgenSampleFileList=/test/poss_chromosomes.txt " \
          "--statsFileBgenSnps=/test/" + association_pack['tarball_prefix'] + ".markers.bgen.stats.gz"
    if len(association_pack['quant_covars']) > 0:
        for covar in association_pack['quant_covars']:
            cmd += " --qCovarCol=" + covar + " "
    if len(association_pack['cat_covars']) > 0:
        for covar in association_pack['cat_covars']:
            cmd += " --covarCol=" + covar + " "
    run_cmd(cmd, True, association_pack['tarball_prefix'] + ".BOLT.markers.log")


# Run rare variant association testing using REGENIE (WARNING: DEPRECATED)
def regenie(association_pack: dict) -> None:

    # Run initial model fitting for REGNIE
    cmd = "regenie " \
          "--step 1 " \
          "--threads 16 " \
          "--bed /test/genetics/UKBB_450K_Autosomes_QCd " \
          "--exclude /test/genetics/UKBB_450K_Autosomes_QCd.low_MAC.snplist " \
          "--remove /test/MODEL_exclude.txt " \
          "--covarFile /test/covariates.formatted.txt " \
          "--covarColList age,sex,PC{1:10} " \
          "--maxCatLevels 110 " \
          "--phenoFile /test/phenotypes.formatted.txt " \
          "--phenoCol " + association_pack['pheno_name'] + " " \
          "--bsize 100 " \
          "--out /test/regenie_fit " \
          "--lowmem "
    if association_pack['is_binary']:
        cmd = cmd + "--bt"
    else:
        cmd = cmd + "--qt"
    run_cmd(cmd, True)

    # Now run actual fit:
    cmd = "./regenie " \
          "--step 2 " \
          "--threads 16 " \
          "--pgen /test/" + association_pack['tarball_prefix'] + ".REGENIE " \
          "--remove /test/MODEL_exclude.txt " \
          "--covarFile /test/covariates.formatted.txt " \
          "--phenoFile /test/phenotypes.formatted.txt " \
          "--firth --approx " \
          "--pred /test/regenie_fit.list " \
          "--ano-file /test/" + association_pack['tarball_prefix'] + ".REGENIE.annotation " \
          "--set-list /test/" + association_pack['tarball_prefix'] + ".REGENIE.setfile " \
          "--mask-def /test/" + association_pack['tarball_prefix'] + ".REGNIE.mask " \
          "--aaf-bins 1 " \
          "--write-mask " \
          "--bsize 200 " \
          "--out /test/regenie_fit_firth "
    if association_pack['is_binary']:
        cmd = cmd + "--bt"
    else:
        cmd = cmd + "--qt"
    run_cmd(cmd, True)


# Run rare variant association testing using SAIGE-GENE
def saige_step_one(association_pack: dict) -> None:

    # See the README.md for more information on these parameters
    cmd = "step1_fitNULLGLMM.R " \
          "--plinkFile=/test/genetics/UKBB_450K_Autosomes_QCd_WBA " \
          "--phenoFile=/test/phenotypes_covariates.formatted.txt " \
          "--phenoCol=" + association_pack['pheno_name'] + " " \
          "--isCovariateTransform=FALSE " \
          "--sampleIDColinphenoFile=IID " \
          "--outputPrefix=/test/" + association_pack['tarball_prefix'] + ".SAIGE_OUT " \
          "--outputPrefix_varRatio=/test/" + association_pack['tarball_prefix'] + ".SAIGE_OUT_cate " \
          "--sparseGRMFile=/test/genetics/sparseGRM_450K_Autosomes_QCd_relatednessCutoff_0.125_2000_randomMarkersUsed.sparseGRM.mtx " \
          "--sparseGRMSampleIDFile=/test/genetics/sparseGRM_450K_Autosomes_QCd_relatednessCutoff_0.125_2000_randomMarkersUsed.sparseGRM.mtx.sampleIDs.txt " \
          "--nThreads=" + str(association_pack['threads']) + " " \
          "--LOCO=FALSE " \
          "--skipModelFitting=FALSE " \
          "--IsSparseKin=TRUE " \
          "--isCateVarianceRatio=TRUE " \
          "--useSparseGRMtoFitNULL=TRUE "
    if association_pack['sex'] == 2:
        if len(association_pack['quant_covars']) > 0:
            quant_covars_join = ','.join(association_pack['quant_covars'])
            cmd = cmd + "--covarColList=PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,age,age_squared,sex," + quant_covars_join + " "
        else:
            cmd = cmd + "--covarColList=PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,age,age_squared,sex "
    else:
        cmd = cmd + "--covarColList=PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,age,age_squared "
    if association_pack['is_binary']:
        cmd = cmd + "--traitType=binary"
    else:
        cmd = cmd + "--traitType=quantitative"
    run_cmd(cmd, True, association_pack['tarball_prefix'] + ".SAIGE_step1.log")


# This is a helper function to parallelise SAIGE step 2 by chromosome
# This returns the chromosome number to make it easier to generate output
def saige_step_two(association_pack: dict, chromosome: str) -> str:

    cmd = "bcftools view --threads 1 -S /test/SAMPLES_Include.txt -Oz -o /test/saige_input." + chromosome + ".vcf.gz /test/" + association_pack['tarball_prefix'] + "." + chromosome + ".SAIGE.bcf"
    run_cmd(cmd, True)
    cmd = "bcftools index --threads 1 /test/saige_input." + chromosome + ".vcf.gz"
    run_cmd(cmd, True)

    # See the README.md for more information on these parameters
    cmd = "step2_SPAtests.R " \
          "--vcfFile=/test/saige_input." + chromosome + ".vcf.gz " \
          "--vcfField=GT " \
          "--GMMATmodelFile=/test/" + association_pack['tarball_prefix'] + ".SAIGE_OUT.rda " \
          "--varianceRatioFile=/test/" + association_pack['tarball_prefix'] + ".SAIGE_OUT_cate.varianceRatio.txt " \
          "--sparseSigmaFile=/test/" + association_pack['tarball_prefix'] + ".SAIGE_OUT_cate.varianceRatio.txt_relatednessCutoff_0.125_2000_randomMarkersUsed.sparseSigma.mtx " \
          "--LOCO=FALSE " \
          "--SAIGEOutputFile=/test/" + association_pack['tarball_prefix'] + "." + chromosome + ".SAIGE_OUT.SAIGE.gene.txt " \
          "--groupFile=/test/" + association_pack['tarball_prefix'] + "." + chromosome + ".SAIGE.groupFile.txt " \
          "--IsSingleVarinGroupTest=TRUE " \
          "--MACCutoff_to_CollapseUltraRare=0.5 " \
          "--IsOutputBETASEinBurdenTest=TRUE"
    run_cmd(cmd, True)

    return(chromosome)


# Run rare variant association testing using STAAR
# Returns the finished chromosome to aid in output file creation
def staar(association_pack: dict, chromosome: str) -> str:

    # I have made a custom script in order to run STAAR:
    # located in /usr/bin/runSTAAR.R
    # This generates a text output file of p.values
    # See the README.md for more information on these parameters
    cmd = "Rscript /prog/runSTAAR.R " \
          "/test/" + association_pack['tarball_prefix'] + "." + chromosome + ".STAAR.matrix.rds " \
          "/test/" + association_pack['tarball_prefix'] + "." + chromosome + ".variants_table.STAAR.tsv " \
          "/test/" + association_pack['tarball_prefix'] + "." + chromosome + ".REGENIE.annotation " \
          "/test/phenotypes_covariates.formatted.txt " + \
          association_pack['pheno_name'] + " " + \
          association_pack['tarball_prefix'] + " " + \
          chromosome + " " + \
          str(association_pack['is_binary'])
    if len(association_pack['quant_covars']) > 0:
        cmd += " " + ','.join(association_pack['quant_covars'])
    else:
        cmd += " NULL"
    if len(association_pack['cat_covars']) > 0:
        cmd += " " + ','.join(association_pack['cat_covars'])
    else:
        cmd += " NULL"
    run_cmd(cmd, True)

    return chromosome


# Setup linear models:
def linear_model_setup(association_pack: dict) -> dict:

    # load covariates and phenotypes
    pheno_covars = pd.read_csv("phenotypes_covariates.formatted.txt",
                               sep=" ",
                               index_col="FID",
                               dtype={'IID':str})
    pheno_covars.index = pheno_covars.index.astype(str)
    poss_indv = set(pheno_covars.index.to_list())

    # load genes/genetic data we want to test/use:
    genes = []
    geno_tables = []
    samples_obtained = False
    for chromosome in CHROMOSOMES:
        # This handles the genes that we need to test:
        if exists(association_pack['tarball_prefix'] + "." + chromosome + ".BOLT.bgen"):

            with open(association_pack['tarball_prefix'] + '.' + chromosome + '.REGENIE.inclusion', 'r') as genes_to_include:
                for gene in genes_to_include:
                    genes.append(gene.rstrip())
                genes_to_include.close()

            # This handles the actual genetic data:
            # load genetic data
            # first convert into format we can use:
            cmd = "plink2 --threads 1 --bgen /test/" + association_pack['tarball_prefix'] + "." + chromosome + ".BOLT.bgen 'ref-last' --export bcf --out /test/lm." + chromosome
            run_cmd(cmd, True)
            # This just makes a sparse matrix with columns: sample_id, gene name, genotype
            cmd = "bcftools query -i \"GT='alt'\" -f \"[%SAMPLE\\t%ID\\t%GT\\n]\" /test/lm." + chromosome + ".bcf > lm." + chromosome + ".tsv"
            run_cmd(cmd, True)

            # First one we find, get the samples we need to match on for the phenotype file...
            if samples_obtained == False:
                # Get individuals to include
                cmd = "bcftools query -l /test/lm." + chromosome + ".bcf > samples_lm." + chromosome + ".txt"
                run_cmd(cmd, True)
                samples_to_include = open('samples_lm.' + chromosome + '.txt', 'r')
                includes = []
                for id in samples_to_include:
                    id = id.rstrip().split("_")[0]
                    if id in poss_indv:
                        includes.append(id)
                samples_to_include.close()
                # include only WES samples from the covariates table:
                pheno_covars = pheno_covars.loc[includes]
                samples_obtained = True

            geno_table = pd.read_csv("lm." + chromosome + ".tsv",
                                     sep = "\t",
                                     names = ['eid', 'gene', 'gt'])
            # VCF stores samples in eid_eid format, so get just the first eid
            geno_table[['eid','eid2']] = geno_table['eid'].str.split('_', 1, expand=True)
            geno_table = geno_table.drop('eid2', axis=1)
            geno_tables.append(geno_table)

    # And concatenate the final data_frame together:
    genetic_data = pd.concat(geno_tables)

    # Decide what model family to use:
    if association_pack['is_binary']:
        family = sm.families.Binomial()
    else:
        family = sm.families.Gaussian()

    # And finally define the formula to be used by all models:
    # Make sure to define additional covariates as requested by the user...
    form = association_pack['pheno_name'] + ' ~ has_var + sex + age + age_squared + C(wes_batch) + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10'
    if len(association_pack['quant_covars']) > 0:
        for covar in association_pack['quant_covars']:
            form += ' + ' + covar
    if len(association_pack['cat_covars']) > 0:
        for covar in association_pack['cat_covars']:
            form += ' + C(' + covar + ')'

    print('Using the following formula for GLMs: ')
    print(form)

    return {'genes': genes,
            'phenotypes': pheno_covars,
            'genotypes': genetic_data,
            'model_family': family,
            'model_formula': form,
            'n_model': len(pheno_covars)}


# Run rare variant association testing using GLMs
def linear_model(linear_model_pack: dict, gene: str) -> dict:

    # Now successively iterate through each gene and run our model:
    # I think this is straight-forward?
    try:
        indv_w_var = linear_model_pack['genotypes'].loc[linear_model_pack['genotypes']['gene'] == gene]['eid'].to_list()
        if len(indv_w_var) == 0:
            gene_dict = {'p_val': 'NA',
                         'effect': 'NA',
                         'std_err': 'NA',
                         'n_car': 0,
                         'n_model': linear_model_pack['n_model'],
                         'gene': gene}
        else:
            # We have to make an internal copy as this DataFrame is NOT threadsafe...
            internal_frame = pd.DataFrame.copy(linear_model_pack['phenotypes'])
            internal_frame['has_var'] = np.where(linear_model_pack['phenotypes'].index.isin(indv_w_var), 1, 0)
            n_car = len(internal_frame.loc[internal_frame['has_var'] == 1])
            if n_car <= 2:
                gene_dict = {'p_val': 'NA',
                             'effect': 'NA',
                             'std_err': 'NA',
                             'n_car': n_car,
                             'n_model': linear_model_pack['n_model'],
                             'gene': gene}
            else:
                sm_results = sm.GLM.from_formula(linear_model_pack['model_formula'],
                                                 data=internal_frame,
                                                 family=linear_model_pack['model_family']).fit()
                gene_dict = {'p_val': sm_results.pvalues['has_var'],
                             'effect': sm_results.params['has_var'],
                             'std_err': sm_results.bse['has_var'],
                             'n_car': n_car,
                             'n_model': sm_results.nobs,
                             'gene': gene}
        return gene_dict

    except Exception as err:
        print(Exception, err)
        raise Exception("Gene " + gene + " failed to run properly...")


@dxpy.entry_point('main')
def main(association_tarball,
         run_bolt,
         run_staar,
         run_regenie,
         run_saige,
         run_linear_model,
         run_all,
         is_binary,
         sex,
         exclusion_list,
         inclusion_list,
         phenofile,
         covarfile,
         categorical_covariates,
         quantitative_covariates,
         output_prefix):

    # First get number of cores available to the instance:
    threads = os.cpu_count()
    print('Number of threads available: %i' % threads)

    if run_bolt is False and run_staar is False and run_regenie is False and run_saige is False and run_linear_model is False and run_all is False:
        raise Exception("No models were selected for execution!")

    # Bring our docker image into our environment so that we can run commands we need:
    cmd = "docker pull egardner413/mrcepid-associationtesting:latest"
    run_cmd(cmd)

    # Grab the data necessary to run this:
    injested_data_info = ingest_data(association_tarball, phenofile, covarfile, inclusion_list, exclusion_list)
    tarball_prefix = injested_data_info['tarball_prefix'] # use in several places so easier to de-identify here

    # This does sample and covariate processing for all pipelines regardless of what we need to run
    # Also returns the phenotype name we are going to test
    genetics_samples = select_individuals(injested_data_info['inclusion_found'],
                                          injested_data_info['exclusion_found'])
    association_pack = create_covariate_file(sex,
                                             genetics_samples,
                                             injested_data_info['additional_covariates_found'],
                                             categorical_covariates,
                                             quantitative_covariates)
    print("Phenotype: " + association_pack['pheno_name'])

    # Attach additional required information to the 'association_pack' variable to enable easy function running:
    association_pack['tarball_prefix'] = tarball_prefix
    association_pack['is_binary'] = is_binary
    association_pack['sex'] = sex
    association_pack['threads'] = threads

    # Run models that were selected – first checking if 'run_all' is enabled:
    output_files = [] # Create a list of outputs to drop into the tarball later
    if run_all:
        run_bolt = True
        run_saige = True
        run_staar = True
        run_linear_model = True

    # Then run selected models
    # Set up a thread pool executor to parallelise by chromosome where required:
    # Need to pare down tested samples to those in the covariate file using bcftools:
    # Running each chromosome on a separate thread to speed things up
    available_workers = association_pack['threads'] - 1
    executor = ThreadPoolExecutor(max_workers=available_workers)

    if run_bolt:
        print("Running BOLT")
        bolt(association_pack)
        output_files.append(association_pack['tarball_prefix'] + ".stats.gz")
        output_files.append(association_pack['tarball_prefix'] + ".bgen.stats.gz")
        output_files.append(association_pack['tarball_prefix'] + ".markers.stats.gz")
        output_files.append(association_pack['tarball_prefix'] + ".markers.bgen.stats.gz")
        output_files.append(association_pack['tarball_prefix'] + ".BOLT.log")
        output_files.append(association_pack['tarball_prefix'] + ".BOLT.markers.log")
    if run_regenie: # this is deprecated
        print("Running REGENIE")
        regenie(association_pack)
        output_files.append(association_pack['tarball_prefix'] + ".regenie_fit_firth_LOY_combined.regenie")
    if run_saige:
        # Run step one without parallelisation
        print("Running SAIGE step 1...")
        saige_step_one(association_pack)

        # Run step two WITH parallelisation by chromosome
        print("Running SAIGE step 2...")
        future_pool = []
        for chromosome in CHROMOSOMES:
            if exists(association_pack['tarball_prefix'] + "." + chromosome + ".SAIGE.bcf"):
                future_pool.append(executor.submit(saige_step_two,
                                                   association_pack = association_pack,
                                                   chromosome = chromosome))

        # And gather the resulting futures
        for future in futures.as_completed(future_pool):
            try:
                finished_chromosome = future.result()
                # output_files.append(association_pack['tarball_prefix'] + ".SAIGE_OUT.rda")
                # output_files.append(association_pack['tarball_prefix'] + ".SAIGE_OUT_cate.varianceRatio.txt")
                output_files.append(association_pack['tarball_prefix'] + ".SAIGE_step1.log")
                output_files.append(association_pack['tarball_prefix'] + "." + finished_chromosome + ".SAIGE_OUT.SAIGE.gene.txt")
                output_files.append(association_pack['tarball_prefix'] + "." + finished_chromosome + ".SAIGE_OUT.SAIGE.gene.txt_single")
            except Exception as err:
                print("A thread failed...")
                print(Exception, err)
                raise dxpy.AppError("A SAIGE thread failed...")
    if run_staar:
        print("Running STAAR")
        future_pool = []
        for chromosome in CHROMOSOMES:
            if exists(tarball_prefix + "." + chromosome + ".STAAR.matrix.rds"):
                future_pool.append(executor.submit(staar,
                                                   association_pack = association_pack,
                                                   chromosome = chromosome))

        # And gather the resulting futures
        for future in futures.as_completed(future_pool):
            try:
                finished_chromosome = future.result()
                output_files.append(association_pack['tarball_prefix'] + "." + finished_chromosome + ".STAAR_results.tsv")
            except Exception as err:
                print("A thread failed...")
                print(Exception, err)
                raise dxpy.AppError("A STAAR thread failed...")
        # Also add the null model for chromosome 1 to the file...
        output_files.append(association_pack['tarball_prefix'] + ".1.STAAR_null.rds")
    if run_linear_model:
        print("Running Linear Models")

        # First, do setup for the linear models.
        # This will load all variants, genes, and phenotypes into memory to allow for parallelization
        # This function returns a dictionary with the following keys:
        # 'genes': The list of genes to iterate over
        # 'phenotypes': Phenotypes/covariates for every individual
        # 'genotypes': Sparse matrix of genotypes in pandas data.frame format
        # 'model_family': Model family for all linear models
        # 'model_formula': Formatted formula for all linear models
        # 'n_model': Number of individuals with values in the pheno/covariate file (do this here to save compute in threads)
        linear_model_pack = linear_model_setup(association_pack)

        # Next we are going to iterate through every gene in linear_model_pack['genes'] and run a linear model
        future_pool = []
        for gene in linear_model_pack['genes']:
            future_pool.append(executor.submit(linear_model,
                                               linear_model_pack = linear_model_pack,
                                               gene = gene))

        # Write results:
        lm_stats_file = open(association_pack['tarball_prefix'] + ".lm_stats.tsv", 'w')
        lm_stats_writer = csv.DictWriter(lm_stats_file, delimiter = "\t", fieldnames=['gene','p_val','effect','std_err','n_car','n_model'])
        lm_stats_writer.writeheader()
        for future in futures.as_completed(future_pool):
            try:
                finished_gene = future.result()
                lm_stats_writer.writerow(finished_gene)
            except Exception as err:
                print(Exception, err)
                # raise dxpy.AppError("A GLM thread for gene" + " failed...")

        output_files.append(association_pack['tarball_prefix'] + ".lm_stats.tsv")
        lm_stats_file.close()

    # Create tar of all possible output files
    if output_prefix is None:
        output_tarball = "assoc_stats.tar.gz"
    else:
        output_tarball = output_prefix + ".assoc_stats.tar.gz"

    tar = tarfile.open(output_tarball, "w:gz")
    for file in output_files:
        tar.add(file)
    tar.close()

    ## Have to do 'upload_local_file' to make sure the new file is registered with dna nexus
    output = {"output_tarball": dxpy.dxlink(dxpy.upload_local_file(output_tarball))}

    return output


dxpy.run()
